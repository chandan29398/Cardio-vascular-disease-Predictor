{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acc41222",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9114adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 1. Load test data ===\n",
    "test_df = pd.read_csv(\"test_kaggle_features.csv\")\n",
    "test_ids = test_df[\"id\"]\n",
    "test_df.drop(columns=[\"id\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "019d36e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_38700\\3978930538.py:4: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  test_df.replace({'Yes': 1, 'No': 0}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# === 2. Preprocess test data (same as training) ===\n",
    "test_df[\"age_years\"] = (test_df[\"age\"] / 365).astype(int)\n",
    "test_df.drop(columns=\"age\", inplace=True)\n",
    "test_df.replace({'Yes': 1, 'No': 0}, inplace=True)\n",
    "\n",
    "# One-hot encoding (same columns as training)\n",
    "categorical_cols = [\"gender\", \"cholesterol\", \"gluc\"]\n",
    "test_df = pd.get_dummies(test_df, columns=categorical_cols, prefix=categorical_cols, drop_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bd264f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 10 model features: ['cholesterol_3', 'gluc_3', 'age_years', 'weight', 'smoke', 'active', 'ap_lo', 'alco', 'gender_2', 'ap_hi']\n",
      "       cholesterol_3  gluc_3  age_years  weight  smoke  active  ap_lo  alco  \\\n",
      "0              False   False         53    59.5      0       1     85     0   \n",
      "1              False   False         57    59.0      0       1     90     0   \n",
      "2              False   False         41    88.0      0       1     80     0   \n",
      "3              False   False         51    62.0      0       1     90     0   \n",
      "4              False   False         49    81.0      0       1     80     0   \n",
      "...              ...     ...        ...     ...    ...     ...    ...   ...   \n",
      "13995          False    True         57    88.0      0       1    100     0   \n",
      "13996          False   False         61   105.0      0       1     90     0   \n",
      "13997          False   False         59    87.0      0       1   1100     0   \n",
      "13998          False   False         50    73.0      0       1     80     0   \n",
      "13999          False   False         57    87.0      0       1     90     0   \n",
      "\n",
      "       gender_2  ap_hi  \n",
      "0         False    120  \n",
      "1         False    130  \n",
      "2          True    120  \n",
      "3          True    120  \n",
      "4         False    120  \n",
      "...         ...    ...  \n",
      "13995     False    160  \n",
      "13996      True    140  \n",
      "13997     False    160  \n",
      "13998     False    120  \n",
      "13999      True    140  \n",
      "\n",
      "[14000 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "# === 3. Align test data to model features ===\n",
    "import numpy as np\n",
    "\n",
    "raw_features = joblib.load(\"model_features.pkl\")\n",
    "model_features = list(np.array(raw_features).flatten())\n",
    "model_features = [str(f) for f in model_features if isinstance(f, str)]\n",
    "model_features = list(dict.fromkeys(model_features))  # Remove duplicates\n",
    "print(f\"Loaded {len(model_features)} model features:\", model_features)\n",
    "\n",
    "# Add any missing columns with default 0\n",
    "for col in model_features:\n",
    "    if col not in test_df.columns:\n",
    "        test_df[col] = 0\n",
    "\n",
    "test_df = test_df[model_features].copy() \n",
    "\n",
    "print(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52ca4319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 4. Scale test data ===\n",
    "scaler = StandardScaler()\n",
    "test_scaled = scaler.fit_transform(test_df)  # You can also load scaler if saved, for exact scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f002904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 5. Load model and predict ===\n",
    "model = joblib.load(\"best_model_tuned_Gradient_Boosting.pkl\")\n",
    "predictions = model.predict(test_scaled)\n",
    "pred_labels = [\"Yes\" if p == 1 else \"No\" for p in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "336a385a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved as 'submission_final.csv'\n"
     ]
    }
   ],
   "source": [
    "# === 6. Save submission ===\n",
    "submission_df = pd.DataFrame({\n",
    "    \"id\": test_ids,\n",
    "    \"cardio\": pred_labels\n",
    "})\n",
    "submission_df.to_csv(\"submission_final.csv\", index=False)\n",
    "print(\"Submission file saved as 'submission_final.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
